---
title: "PML_courseraProject"
author: "ansprasad"
date: "3/13/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



## Coursera Project - Practical Machine Learning

### Loading Libraries

```{r loading libraries required, message=FALSE}
library(ggplot2)
library(caret)
library(doParallel)
library(e1071)
library(gbm)
library(survival)
library(splines)
library(plyr)
```
### Loading Data 
Data is loaded after removing Div/0!
```{r loading data}
training <- read.csv("pml-training.csv", na.strings=c("#DIV/0!"), row.names = 1)
testing <- read.csv("pml-testing.csv", na.strings=c("#DIV/0!"), row.names = 1)
```

### Cleaning NA and blank Columns 
Totally there were 174 columns of loaded data after the previous step. However, there are several column which have high % of blank or NA data. Removing them should improve model performance. hence cleaning them up and creating good column list
```{r Cleaning columns}
training <- training[, 6:dim(training)[2]]
treshold <- dim(training)[1] * 0.95
goodcols <- !apply(training, 2, function(x) sum(is.na(x)) > treshold  || sum(x=="") > treshold)
training <- training[, goodcols]
badcols <- nearZeroVar(training, saveMetrics = TRUE)
training <- training[, badcols$nzv==FALSE]
training$classe = factor(training$classe)
names(training)
```

### Training data preparation
We had around 53 good columns and the class "classe".121 columns were discarded. All classes are to an extent represented well. Based on initial model build (model saved as RDS file "fullmodel.RDS"), top 23 (see png file) were selected.
Preparing data for training and crossvalidation with the training dataset provided. Training set divided into test and train for crossvalidation
```{r Training and crossvalidation set prepared with selected columns}
colsfin <- c("num_window","roll_belt","pitch_forearm","yaw_belt","magnet_dumbbell_z","magnet_dumbbell_y","roll_forearm","pitch_belt","magnet_belt_z","roll_dumbbell","accel_dumbbell_z","gyros_belt_z","accel_forearm_x","accel_dumbbell_y","gyros_dumbbell_y","accel_dumbbell_x","magnet_forearm_z","roll_arm","yaw_arm","gyros_arm_y","gyros_belt_y","magnet_belt_x","magnet_forearm_x")
training1 <- training[colsfin]
training1$classe <- training$classe
inTrain <- createDataPartition(training1$classe, p = 0.6)[[1]]
crossv <- training1[-inTrain,]
training1 <- training1[ inTrain,]
inTrain <- createDataPartition(crossv$classe, p = 0.75)[[1]]
crossv_test <- crossv[ -inTrain,]
crossv <- crossv[inTrain,]
```

###Test data preparation similar to training
```{r Test data preparation}
testing <- testing[, 6:dim(testing)[2]]
testing <- testing[, goodcols]
testing$classe <- NA
testing <- testing[, badcols$nzv==FALSE]
testing1 <- testing[colsfin]
testing1$classe <- NA
```

### Building boost model and predicting with cross Validation 
initially thought of Random forest too and since it was taking too much time and previous quiz results providing a clue to lean towards boosting. selected boosting
model was built using

modgbm <- train(classe ~ ., data=training1, method="gbm",verbose=F)

and saved in workspace as truncatedmodel.RDS using

saveRDS(modgbm,"truncatedmodel.RDS")


```{r Boosting model building (loading to reduce memory issues)}
modgbm <- readRDS("truncatedmodel.RDS")
```
### predicting using built model

```{r Predicting using built model}
predgbm <- predict(modgbm, crossv)
confusionMatrix(predgbm, crossv$classe)
accuracygbm <- sum(predgbm == crossv_test$classe) / length(predgbm)
```


### Important Features
Important features were computed using gradient boosting using
varImpGBM <- train(classe ~ ., data = training1, method = "gbm",verbose=F)
and the model was saved in "varImpGBM.RDS" in workspace using
saveRDS(varImpGBM,"varImpGBM.RDS")
these are not run again due to memory issues in my computer during knitting as html as mentioned earlier.


```{r Important Variables}
varImpGBM <- readRDS("varImpGBM.RDS")
varImpObj <- varImp(varImpGBM)
```
### Plotting important features obtained from previous step
```{r plotting important features}
plot(varImpObj, main = "Importance of Variables")
```



### Results and Conclusion
Model size reduction to 23 was carried out based on an initial run which has not been compiled in html due to memory.limit() available in my computer being 7989. hence the classification happened with just 23 out of the 53 features available after data cleansing. Since, even 23rd feature has some amount of good importance and since and the out of sample accuracy obtained is >99%, stopped with the same instead of checking with further lesser features


### ANSWERS for the quiz from the developed model have been found using the code segment below. the answers are written both to file and to console


```{r writing answers,echo=TRUE}
path0<-getwd()
pml_write_files = function(x){
n = length(x)
for(i in 1:n){
filename = paste0(path0,"/problem_id_",i,".txt")
write.table(x[i],file=filename,quote=FALSE,row.names=FALSE,col.names=FALSE)
}
}

x <- testing1
answers <- predict(modgbm, newdata=x)
answers
pml_write_files(answers)
```


